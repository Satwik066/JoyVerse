{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzIcBOalQqJo",
        "outputId": "c8f3eee8-3958-41e2-8395-f28002603fda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install torch pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "GHtXG0kZVsBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"JoyVerseDataSet.csv\")\n",
        "\n",
        "# Extract labels and features\n",
        "labels = df['Expression'].values\n",
        "features = df.drop(columns=['Expression']).values\n",
        "\n",
        "# Reshape to (samples, 468, 3)\n",
        "features = features.reshape((features.shape[0], 468, 3))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "a0o5mLisV1Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class FaceMeshDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = FaceMeshDataset(X_train, y_train)\n",
        "test_dataset = FaceMeshDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n"
      ],
      "metadata": {
        "id": "KMmwOY-zWDUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceMeshTransformer(nn.Module):\n",
        "    def __init__(self, input_dim=3, model_dim=64, num_heads=4, num_layers=2, num_classes=5):\n",
        "        super(FaceMeshTransformer, self).__init__()\n",
        "        self.embedding = nn.Linear(input_dim, model_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(468 * model_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # (batch, seq_len, model_dim)\n",
        "        x = x.permute(1, 0, 2)  # (seq_len, batch, model_dim)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # back to (batch, seq_len, model_dim)\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "w6FvmpDyWGwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = FaceMeshTransformer(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def train_model(model, loader, criterion, optimizer, epochs=100):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pprarloIWOk6",
        "outputId": "ba9968de-e168-44e5-dabc-e9ac9d0a9f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 125.5695\n",
            "Epoch 2/100, Loss: 33.4924\n",
            "Epoch 3/100, Loss: 28.3439\n",
            "Epoch 4/100, Loss: 28.5115\n",
            "Epoch 5/100, Loss: 28.4597\n",
            "Epoch 6/100, Loss: 28.4078\n",
            "Epoch 7/100, Loss: 28.3571\n",
            "Epoch 8/100, Loss: 28.3077\n",
            "Epoch 9/100, Loss: 28.2748\n",
            "Epoch 10/100, Loss: 28.2182\n",
            "Epoch 11/100, Loss: 28.1606\n",
            "Epoch 12/100, Loss: 28.1403\n",
            "Epoch 13/100, Loss: 28.0957\n",
            "Epoch 14/100, Loss: 28.0444\n",
            "Epoch 15/100, Loss: 28.0060\n",
            "Epoch 16/100, Loss: 27.9604\n",
            "Epoch 17/100, Loss: 27.9287\n",
            "Epoch 18/100, Loss: 27.9275\n",
            "Epoch 19/100, Loss: 27.8643\n",
            "Epoch 20/100, Loss: 27.8539\n",
            "Epoch 21/100, Loss: 27.8077\n",
            "Epoch 22/100, Loss: 27.7574\n",
            "Epoch 23/100, Loss: 27.7396\n",
            "Epoch 24/100, Loss: 27.7278\n",
            "Epoch 25/100, Loss: 27.7135\n",
            "Epoch 26/100, Loss: 27.6553\n",
            "Epoch 27/100, Loss: 27.6338\n",
            "Epoch 28/100, Loss: 27.6007\n",
            "Epoch 29/100, Loss: 27.5971\n",
            "Epoch 30/100, Loss: 27.5853\n",
            "Epoch 31/100, Loss: 27.5393\n",
            "Epoch 32/100, Loss: 27.5085\n",
            "Epoch 33/100, Loss: 27.5139\n",
            "Epoch 34/100, Loss: 27.4680\n",
            "Epoch 35/100, Loss: 27.4470\n",
            "Epoch 36/100, Loss: 27.4974\n",
            "Epoch 37/100, Loss: 27.4298\n",
            "Epoch 38/100, Loss: 27.4060\n",
            "Epoch 39/100, Loss: 27.3880\n",
            "Epoch 40/100, Loss: 27.3588\n",
            "Epoch 41/100, Loss: 27.3575\n",
            "Epoch 42/100, Loss: 27.3545\n",
            "Epoch 43/100, Loss: 27.3416\n",
            "Epoch 44/100, Loss: 27.3265\n",
            "Epoch 45/100, Loss: 27.3549\n",
            "Epoch 46/100, Loss: 27.3017\n",
            "Epoch 47/100, Loss: 27.3044\n",
            "Epoch 48/100, Loss: 27.2884\n",
            "Epoch 49/100, Loss: 27.2284\n",
            "Epoch 50/100, Loss: 27.2444\n",
            "Epoch 51/100, Loss: 27.2046\n",
            "Epoch 52/100, Loss: 27.2901\n",
            "Epoch 53/100, Loss: 27.2721\n",
            "Epoch 54/100, Loss: 27.2471\n",
            "Epoch 55/100, Loss: 27.2291\n",
            "Epoch 56/100, Loss: 27.1964\n",
            "Epoch 57/100, Loss: 27.2215\n",
            "Epoch 58/100, Loss: 27.1810\n",
            "Epoch 59/100, Loss: 27.1953\n",
            "Epoch 60/100, Loss: 27.1717\n",
            "Epoch 61/100, Loss: 27.2268\n",
            "Epoch 62/100, Loss: 27.2078\n",
            "Epoch 63/100, Loss: 27.1703\n",
            "Epoch 64/100, Loss: 27.1303\n",
            "Epoch 65/100, Loss: 27.1390\n",
            "Epoch 66/100, Loss: 27.1177\n",
            "Epoch 67/100, Loss: 27.1437\n",
            "Epoch 68/100, Loss: 27.1130\n",
            "Epoch 69/100, Loss: 27.1225\n",
            "Epoch 70/100, Loss: 27.1491\n",
            "Epoch 71/100, Loss: 27.1079\n",
            "Epoch 72/100, Loss: 27.0882\n",
            "Epoch 73/100, Loss: 27.0810\n",
            "Epoch 74/100, Loss: 27.1130\n",
            "Epoch 75/100, Loss: 27.0414\n",
            "Epoch 76/100, Loss: 27.0376\n",
            "Epoch 77/100, Loss: 27.0760\n",
            "Epoch 78/100, Loss: 27.0679\n",
            "Epoch 79/100, Loss: 27.0923\n",
            "Epoch 80/100, Loss: 27.1171\n",
            "Epoch 81/100, Loss: 27.1191\n",
            "Epoch 82/100, Loss: 27.0510\n",
            "Epoch 83/100, Loss: 27.0333\n",
            "Epoch 84/100, Loss: 27.1052\n",
            "Epoch 85/100, Loss: 27.0616\n",
            "Epoch 86/100, Loss: 27.0435\n",
            "Epoch 87/100, Loss: 27.0951\n",
            "Epoch 88/100, Loss: 27.0839\n",
            "Epoch 89/100, Loss: 27.1089\n",
            "Epoch 90/100, Loss: 27.0435\n",
            "Epoch 91/100, Loss: 27.1167\n",
            "Epoch 92/100, Loss: 27.0788\n",
            "Epoch 93/100, Loss: 27.0390\n",
            "Epoch 94/100, Loss: 26.9843\n",
            "Epoch 95/100, Loss: 27.0341\n",
            "Epoch 96/100, Loss: 27.0504\n",
            "Epoch 97/100, Loss: 27.1166\n",
            "Epoch 98/100, Loss: 27.0730\n",
            "Epoch 99/100, Loss: 27.0361\n",
            "Epoch 100/100, Loss: 27.0336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_classes = label_encoder.classes_\n",
        "print(\"Emotion classes:\", emotion_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d5oq1naWUbA",
        "outputId": "900f08e4-15ab-4f5a-ebe8-f4fe18d18359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion classes: ['Angry' 'Disgust' 'Fear' 'Happy' 'Neutral' 'Sad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            outputs = model(batch_X)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=emotion_classes))\n",
        "    print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
        "\n",
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlf0g2LKWYfx",
        "outputId": "2b7c8bd5-f6d6-41fc-b9f7-a0ab6b0c193b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.00      0.00      0.00        11\n",
            "     Disgust       0.00      0.00      0.00         8\n",
            "        Fear       0.00      0.00      0.00         1\n",
            "       Happy       0.35      1.00      0.52        22\n",
            "     Neutral       0.00      0.00      0.00        11\n",
            "         Sad       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.35        63\n",
            "   macro avg       0.06      0.17      0.09        63\n",
            "weighted avg       0.12      0.35      0.18        63\n",
            "\n",
            "Accuracy: 0.3492063492063492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), \"facemesh_transformer.pth\")\n",
        "\n",
        "# Save the label encoder classes\n",
        "import json\n",
        "with open(\"label_classes.json\", \"w\") as f:\n",
        "    json.dump(emotion_classes.tolist(), f)\n"
      ],
      "metadata": {
        "id": "D4I4-jmGWlEx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}